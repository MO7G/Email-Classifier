{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7f432fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandastable'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandastable\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mToken_type\u001b[39;00m(Enum):  \u001b[38;5;66;03m# listing all tokens type\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandastable'"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from enum import Enum\n",
    "import re\n",
    "import pandas\n",
    "import pandastable as pt\n",
    "from nltk.tree import *\n",
    "\n",
    "\n",
    "class Token_type(Enum):  # listing all tokens type\n",
    "    Begin = 1\n",
    "    End = 2\n",
    "    Do = 3\n",
    "    Else = 4\n",
    "    EndIf = 5\n",
    "    If = 6\n",
    "    Integer = 7\n",
    "    Dot = 8\n",
    "    Semicolon = 9\n",
    "    EqualOp = 10\n",
    "    LessThanOp = 11\n",
    "    GreaterThanOp = 12\n",
    "    NotEqualOp = 13\n",
    "    PlusOp = 14\n",
    "    MinusOp = 15\n",
    "    MultiplyOp = 16\n",
    "    DivideOp = 17\n",
    "    Identifier = 18\n",
    "    Constant = 19\n",
    "    Program = 20\n",
    "    Procedure = 21\n",
    "    Parameters = 22\n",
    "    Declare = 23\n",
    "    Error = 24\n",
    "    read = 25\n",
    "    write = 26\n",
    "\n",
    "# class token to hold string and token type\n",
    "class token:\n",
    "    def init(self, lex, token_type):\n",
    "        self.lex = lex\n",
    "        self.token_type = token_type\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'Lex': self.lex,\n",
    "            'token_type': self.token_type\n",
    "        }\n",
    "\n",
    "\n",
    "# Reserved word Dictionary\n",
    "ReservedWords = {\"IF\": Token_type.If,\n",
    "                 \"PROGRAM\": Token_type.Program,\n",
    "                 \"PROCEDURE\": Token_type.Procedure,\n",
    "                 \"Parameters\": Token_type.Parameters,\n",
    "                 \"Declare\": Token_type.Declare,\n",
    "                 \"END\": Token_type.End,\n",
    "                 \"BEGIN\": Token_type.Begin,\n",
    "                 \"DO\": Token_type.Do,\n",
    "                 \"ElSE\": Token_type.Else,\n",
    "                 \"ENDIF\": Token_type.EndIf,\n",
    "                 \"INTEGER\": Token_type.Integer,\n",
    "                 \"read\" : Token_type.read,\n",
    "                 \"write\" : Token_type.write\n",
    "                 }\n",
    "Operators = {\".\": Token_type.Dot,\n",
    "             \";\": Token_type.Semicolon,\n",
    "             \"=\": Token_type.EqualOp,\n",
    "             \"+\": Token_type.PlusOp,\n",
    "             \"-\": Token_type.MinusOp,\n",
    "             \"*\": Token_type.MultiplyOp,\n",
    "             \"/\": Token_type.DivideOp\n",
    "             }\n",
    "Tokens = []\n",
    "errors = []\n",
    "\n",
    "\n",
    "def find_token(text):\n",
    "    lexems = text.split()\n",
    "    for le in lexems:\n",
    "        if (le in ReservedWords):\n",
    "            new_token = token(le, ReservedWords[le])\n",
    "            Tokens.append(new_token)\n",
    "        elif (le in Operators):\n",
    "            new_token = token(le, Operators[le])\n",
    "            Tokens.append(new_token)\n",
    "        elif (re.match(\"^\\d+(\\.[0-9]*)?$\", le)):\n",
    "            new_token = token(le, Token_type.Constant)\n",
    "            Tokens.append(new_token)\n",
    "        elif (re.match(\"^([a-zA-Z][a-zA-Z0-9]*)$\", le)):\n",
    "            new_token = token(le, Token_type.Identifier)\n",
    "            Tokens.append(new_token)\n",
    "        else:\n",
    "            new_token = token(le, Token_type.Error)\n",
    "            errors.append(\"Lexical error  \" + le)\n",
    "\n",
    "\n",
    "def Parse():\n",
    "    j = 0\n",
    "    Children = []\n",
    "    Header_dict=Header(j)\n",
    "    Children.append(Header_dict[\"node\"])\n",
    "    Block_dict = Block(Header_dict[\"index\"])\n",
    "    Children.append(Block_dict[\"node\"])\n",
    "    dic_output = Match(Token_type.Dot, Block_dict[\"index\"])\n",
    "    Children.append(dic_output[\"node\"])\n",
    "\n",
    "\n",
    "    Node = Tree('Program', Children)\n",
    "\n",
    "    return Node\n",
    "\n",
    "\n",
    "def Header(j):\n",
    "    Children =[]\n",
    "    out = dict()\n",
    "    out_pro = Match(Token_type.Program,j)\n",
    "    Children.append(out_pro[\"node\"])\n",
    "    out_id = Match(Token_type.Identifier,out_pro[\"index\"])\n",
    "    Children.append(out_id[\"node\"])\n",
    "    out_sem = Match(Token_type.Semicolon,out_id[\"index\"])\n",
    "    Children.append(out_sem[\"node\"])\n",
    "    node=Tree(\"Header\",Children)\n",
    "    out[\"node\"] = node\n",
    "    out[\"index\"] = out_sem[\"index\"]\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def Block(j):\n",
    "        Children =[]\n",
    "        out = dict()\n",
    "        out_beg = Match(Token_type.Begin,j)\n",
    "        Children.append(out_beg[\"node\"])\n",
    "        Statements_dict = Statements(out_beg[\"index\"])\n",
    "        Children.append(Statements_dict[\"node\"])\n",
    "        out_end = Match(Token_type.End,Statements_dict[\"index\"])\n",
    "        Children.append(out_end[\"node\"])\n",
    "        node = Tree(\"Block\", Children)\n",
    "        out[\"node\"] = node\n",
    "        out[\"index\"] = out_end[\"index\"]\n",
    "        return out\n",
    "\n",
    "\n",
    "def Statements(j):\n",
    "   Children = []\n",
    "   out = dict()\n",
    "\n",
    "   out_rw = dict()\n",
    "\n",
    "   if (j < len(Tokens)):\n",
    "     Temp = Tokens[j].to_dict()\n",
    "     if (Temp[\"token_type\"] ==Token_type.read):\n",
    "       out_rw = Match(Token_type.read, j)\n",
    "\n",
    "\n",
    "     else:\n",
    "       out_rw = Match(Token_type.write,j)\n",
    "\n",
    "     Children.append(out_rw[\"node\"])\n",
    "     out_id = Match(Token_type.Identifier,out_rw[\"index\"])\n",
    "     Children.append(out_id[\"node\"])\n",
    "     node = Tree(\"Statements\",Children)\n",
    "     out[\"node\"] = node\n",
    "     out[\"index\"] = out_id[\"index\"]\n",
    "     return out\n",
    "   out[\"node\"] = 'error'\n",
    "   out[\"index\"] = j + 1\n",
    "   return out\n",
    "\n",
    "def Match(a, j):\n",
    "    output = dict()\n",
    "    if (j < len(Tokens)):\n",
    "        Temp = Tokens[j].to_dict()\n",
    "        if (Temp['token_type'] == a):\n",
    "            j += 1\n",
    "            output[\"node\"] = [Temp['Lex']]\n",
    "            output[\"index\"] = j\n",
    "            return output\n",
    "        else:\n",
    "            output[\"node\"] = [\"error\"]\n",
    "            output[\"index\"] = j\n",
    "            errors.append(\"Syntax error : \" + Temp['Lex'] + \" Expected \" + str(a))\n",
    "            return output\n",
    "    else:\n",
    "        output[\"node\"] = [\"error\"]\n",
    "        output[\"index\"] = j + 1\n",
    "        return output\n",
    "\n",
    "\n",
    "# GUI\n",
    "root = tk.Tk()\n",
    "\n",
    "canvas1 = tk.Canvas(root, width=400, height=300, relief='raised')\n",
    "canvas1.pack()\n",
    "\n",
    "label1 = tk.Label(root, text='Scanner Phase')\n",
    "label1.config(font=('helvetica', 14))\n",
    "canvas1.create_window(200, 25, window=label1)\n",
    "\n",
    "label2 = tk.Label(root, text='Source code:')\n",
    "label2.config(font=('helvetica', 10))\n",
    "canvas1.create_window(200, 100, window=label2)\n",
    "\n",
    "entry1 = tk.Entry(root)\n",
    "canvas1.create_window(200, 140, window=entry1)\n",
    "\n",
    "\n",
    "def Scan():\n",
    "    x1 = entry1.get()\n",
    "    find_token(x1)\n",
    "    df = pandas.DataFrame.from_records([t.to_dict() for t in Tokens])\n",
    "    # print(df)\n",
    "\n",
    "    # to display token stream as table\n",
    "    dTDa1 = tk.Toplevel()\n",
    "    dTDa1.title('Token Stream')\n",
    "    dTDaPT = pt.Table(dTDa1, dataframe=df, showtoolbar=True, showstatusbar=True)\n",
    "    dTDaPT.show()\n",
    "    # start Parsing\n",
    "    Node = Parse()\n",
    "\n",
    "    # to display errorlist\n",
    "    df1 = pandas.DataFrame(errors)\n",
    "    dTDa2 = tk.Toplevel()\n",
    "    dTDa2.title('Error List')\n",
    "    dTDaPT2 = pt.Table(dTDa2, dataframe=df1, showtoolbar=True, showstatusbar=True)\n",
    "    dTDaPT2.show()\n",
    "    Node.draw()\n",
    "    # clear your list\n",
    "\n",
    "    # label3 = tk.Label(root, text='Lexem ' + x1 + ' is:', font=('helvetica', 10))\n",
    "    # canvas1.create_window(200, 210, window=label3)\n",
    "\n",
    "    # label4 = tk.Label(root, text=\"Token_type\"+x1, font=('helvetica', 10, 'bold'))\n",
    "    # canvas1.create_window(200, 230, window=label4)\n",
    "\n",
    "\n",
    "button1 = tk.Button(text='Scan', command=Scan, bg='brown', fg='white', font=('helvetica', 9, 'bold'))\n",
    "canvas1.create_window(200, 180, window=button1)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d53f617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
